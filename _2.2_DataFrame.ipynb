{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = './dataset/train.csv'\n",
    "test_csv_path = './dataset/test.csv'\n",
    "train_images_path = './dataset/train_images'\n",
    "test_images_path = './dataset/test_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Train and Test csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263854</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612J1R1xHl...</td>\n",
       "      <td>558806</td>\n",
       "      <td>height</td>\n",
       "      <td>5.0 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263855</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61Blzh2+28...</td>\n",
       "      <td>470067</td>\n",
       "      <td>height</td>\n",
       "      <td>8.5 inch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263856</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51MsegDL9V...</td>\n",
       "      <td>204245</td>\n",
       "      <td>height</td>\n",
       "      <td>43.2 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263857</th>\n",
       "      <td>https://m.media-amazon.com/images/I/510KhVw4VS...</td>\n",
       "      <td>752266</td>\n",
       "      <td>height</td>\n",
       "      <td>9.1 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263858</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51lzTNLQ-6...</td>\n",
       "      <td>416664</td>\n",
       "      <td>height</td>\n",
       "      <td>27.5 centimetre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263859 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_link  group_id  \\\n",
       "0       https://m.media-amazon.com/images/I/61I9XdN6OF...    748919   \n",
       "1       https://m.media-amazon.com/images/I/71gSRbyXmo...    916768   \n",
       "2       https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516   \n",
       "3       https://m.media-amazon.com/images/I/612mrlqiI4...    459516   \n",
       "4       https://m.media-amazon.com/images/I/617Tl40LOX...    731432   \n",
       "...                                                   ...       ...   \n",
       "263854  https://m.media-amazon.com/images/I/612J1R1xHl...    558806   \n",
       "263855  https://m.media-amazon.com/images/I/61Blzh2+28...    470067   \n",
       "263856  https://m.media-amazon.com/images/I/51MsegDL9V...    204245   \n",
       "263857  https://m.media-amazon.com/images/I/510KhVw4VS...    752266   \n",
       "263858  https://m.media-amazon.com/images/I/51lzTNLQ-6...    416664   \n",
       "\n",
       "        entity_name     entity_value  \n",
       "0       item_weight       500.0 gram  \n",
       "1       item_volume          1.0 cup  \n",
       "2       item_weight       0.709 gram  \n",
       "3       item_weight       0.709 gram  \n",
       "4       item_weight   1400 milligram  \n",
       "...             ...              ...  \n",
       "263854       height   5.0 centimetre  \n",
       "263855       height         8.5 inch  \n",
       "263856       height  43.2 centimetre  \n",
       "263857       height   9.1 centimetre  \n",
       "263858       height  27.5 centimetre  \n",
       "\n",
       "[263859 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_path)\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/110EibNycl...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>width</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11gHj8dhhr...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131182</th>\n",
       "      <td>131283</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rVsIzEtk...</td>\n",
       "      <td>721522</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131183</th>\n",
       "      <td>131284</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rdvZ5zDd...</td>\n",
       "      <td>603688</td>\n",
       "      <td>item_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131184</th>\n",
       "      <td>131285</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rdvZ5zDd...</td>\n",
       "      <td>603688</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131185</th>\n",
       "      <td>131286</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1tnTUPyr7...</td>\n",
       "      <td>853009</td>\n",
       "      <td>item_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131186</th>\n",
       "      <td>131287</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1tnTUPyr7...</td>\n",
       "      <td>853009</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131187 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                         image_link  group_id  \\\n",
       "0            0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n",
       "1            1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "2            2  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "3            3  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "4            4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
       "...        ...                                                ...       ...   \n",
       "131182  131283  https://m.media-amazon.com/images/I/A1rVsIzEtk...    721522   \n",
       "131183  131284  https://m.media-amazon.com/images/I/A1rdvZ5zDd...    603688   \n",
       "131184  131285  https://m.media-amazon.com/images/I/A1rdvZ5zDd...    603688   \n",
       "131185  131286  https://m.media-amazon.com/images/I/A1tnTUPyr7...    853009   \n",
       "131186  131287  https://m.media-amazon.com/images/I/A1tnTUPyr7...    853009   \n",
       "\n",
       "                          entity_name  \n",
       "0                              height  \n",
       "1                               width  \n",
       "2                              height  \n",
       "3                               depth  \n",
       "4                               depth  \n",
       "...                               ...  \n",
       "131182  maximum_weight_recommendation  \n",
       "131183                    item_weight  \n",
       "131184  maximum_weight_recommendation  \n",
       "131185                    item_weight  \n",
       "131186  maximum_weight_recommendation  \n",
       "\n",
       "[131187 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pd.read_csv(test_csv_path)\n",
    "test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Image path columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(i.endswith('.jpg') for i in os.listdir(train_images_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263859, 263859)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_id = []\n",
    "images_path = []\n",
    "\n",
    "for i, link in enumerate(train_csv.image_link.values):\n",
    "    # if i == 10:\n",
    "    #     break\n",
    "    \n",
    "    image_id = link.split(\"/\")[-1].split('.')[0]\n",
    "    image_path = os.path.join(train_images_path, image_id) + '.jpg'\n",
    "    \n",
    "    images_id.append(image_id)\n",
    "    images_path.append(image_path)\n",
    "    # print(link, image_id, image_path, os.path.isfile(image_path))\n",
    "    \n",
    "    \n",
    "len(images_id), len(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "      <td>./dataset/train_images/61I9XdN6OFL.jpg</td>\n",
       "      <td>61I9XdN6OFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "      <td>./dataset/train_images/71gSRbyXmoL.jpg</td>\n",
       "      <td>71gSRbyXmoL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>./dataset/train_images/61BZ4zrjZXL.jpg</td>\n",
       "      <td>61BZ4zrjZXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>./dataset/train_images/612mrlqiI4L.jpg</td>\n",
       "      <td>612mrlqiI4L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "      <td>./dataset/train_images/617Tl40LOXL.jpg</td>\n",
       "      <td>617Tl40LOXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263854</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612J1R1xHl...</td>\n",
       "      <td>558806</td>\n",
       "      <td>height</td>\n",
       "      <td>5.0 centimetre</td>\n",
       "      <td>./dataset/train_images/612J1R1xHlL.jpg</td>\n",
       "      <td>612J1R1xHlL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263855</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61Blzh2+28...</td>\n",
       "      <td>470067</td>\n",
       "      <td>height</td>\n",
       "      <td>8.5 inch</td>\n",
       "      <td>./dataset/train_images/61Blzh2+28L.jpg</td>\n",
       "      <td>61Blzh2+28L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263856</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51MsegDL9V...</td>\n",
       "      <td>204245</td>\n",
       "      <td>height</td>\n",
       "      <td>43.2 centimetre</td>\n",
       "      <td>./dataset/train_images/51MsegDL9VL.jpg</td>\n",
       "      <td>51MsegDL9VL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263857</th>\n",
       "      <td>https://m.media-amazon.com/images/I/510KhVw4VS...</td>\n",
       "      <td>752266</td>\n",
       "      <td>height</td>\n",
       "      <td>9.1 centimetre</td>\n",
       "      <td>./dataset/train_images/510KhVw4VSL.jpg</td>\n",
       "      <td>510KhVw4VSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263858</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51lzTNLQ-6...</td>\n",
       "      <td>416664</td>\n",
       "      <td>height</td>\n",
       "      <td>27.5 centimetre</td>\n",
       "      <td>./dataset/train_images/51lzTNLQ-6S.jpg</td>\n",
       "      <td>51lzTNLQ-6S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263859 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_link  group_id  \\\n",
       "0       https://m.media-amazon.com/images/I/61I9XdN6OF...    748919   \n",
       "1       https://m.media-amazon.com/images/I/71gSRbyXmo...    916768   \n",
       "2       https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516   \n",
       "3       https://m.media-amazon.com/images/I/612mrlqiI4...    459516   \n",
       "4       https://m.media-amazon.com/images/I/617Tl40LOX...    731432   \n",
       "...                                                   ...       ...   \n",
       "263854  https://m.media-amazon.com/images/I/612J1R1xHl...    558806   \n",
       "263855  https://m.media-amazon.com/images/I/61Blzh2+28...    470067   \n",
       "263856  https://m.media-amazon.com/images/I/51MsegDL9V...    204245   \n",
       "263857  https://m.media-amazon.com/images/I/510KhVw4VS...    752266   \n",
       "263858  https://m.media-amazon.com/images/I/51lzTNLQ-6...    416664   \n",
       "\n",
       "        entity_name     entity_value                              image_path  \\\n",
       "0       item_weight       500.0 gram  ./dataset/train_images/61I9XdN6OFL.jpg   \n",
       "1       item_volume          1.0 cup  ./dataset/train_images/71gSRbyXmoL.jpg   \n",
       "2       item_weight       0.709 gram  ./dataset/train_images/61BZ4zrjZXL.jpg   \n",
       "3       item_weight       0.709 gram  ./dataset/train_images/612mrlqiI4L.jpg   \n",
       "4       item_weight   1400 milligram  ./dataset/train_images/617Tl40LOXL.jpg   \n",
       "...             ...              ...                                     ...   \n",
       "263854       height   5.0 centimetre  ./dataset/train_images/612J1R1xHlL.jpg   \n",
       "263855       height         8.5 inch  ./dataset/train_images/61Blzh2+28L.jpg   \n",
       "263856       height  43.2 centimetre  ./dataset/train_images/51MsegDL9VL.jpg   \n",
       "263857       height   9.1 centimetre  ./dataset/train_images/510KhVw4VSL.jpg   \n",
       "263858       height  27.5 centimetre  ./dataset/train_images/51lzTNLQ-6S.jpg   \n",
       "\n",
       "           image_id  \n",
       "0       61I9XdN6OFL  \n",
       "1       71gSRbyXmoL  \n",
       "2       61BZ4zrjZXL  \n",
       "3       612mrlqiI4L  \n",
       "4       617Tl40LOXL  \n",
       "...             ...  \n",
       "263854  612J1R1xHlL  \n",
       "263855  61Blzh2+28L  \n",
       "263856  51MsegDL9VL  \n",
       "263857  510KhVw4VSL  \n",
       "263858  51lzTNLQ-6S  \n",
       "\n",
       "[263859 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv['image_path'] = images_path\n",
    "train_csv['image_id'] = images_id\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131187, 131187)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_id = []\n",
    "images_path = []\n",
    "\n",
    "for i, link in enumerate(test_csv.image_link.values):\n",
    "    # if i == 10:\n",
    "    #     break\n",
    "    \n",
    "    image_id = link.split(\"/\")[-1].split('.')[0]\n",
    "    image_path = os.path.join(test_images_path, image_id) + '.jpg'\n",
    "    \n",
    "    images_id.append(image_id)\n",
    "    images_path.append(image_path)\n",
    "    # print(link, image_id, image_path, os.path.isfile(image_path))\n",
    "    \n",
    "    \n",
    "len(images_id), len(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/110EibNycl...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "      <td>./dataset/test_images/110EibNyclL.jpg</td>\n",
       "      <td>110EibNyclL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>width</td>\n",
       "      <td>./dataset/test_images/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>height</td>\n",
       "      <td>./dataset/test_images/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "      <td>./dataset/test_images/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11gHj8dhhr...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "      <td>./dataset/test_images/11gHj8dhhrL.jpg</td>\n",
       "      <td>11gHj8dhhrL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131182</th>\n",
       "      <td>131283</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rVsIzEtk...</td>\n",
       "      <td>721522</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "      <td>./dataset/test_images/A1rVsIzEtkL.jpg</td>\n",
       "      <td>A1rVsIzEtkL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131183</th>\n",
       "      <td>131284</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rdvZ5zDd...</td>\n",
       "      <td>603688</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>./dataset/test_images/A1rdvZ5zDdL.jpg</td>\n",
       "      <td>A1rdvZ5zDdL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131184</th>\n",
       "      <td>131285</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rdvZ5zDd...</td>\n",
       "      <td>603688</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "      <td>./dataset/test_images/A1rdvZ5zDdL.jpg</td>\n",
       "      <td>A1rdvZ5zDdL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131185</th>\n",
       "      <td>131286</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1tnTUPyr7...</td>\n",
       "      <td>853009</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>./dataset/test_images/A1tnTUPyr7L.jpg</td>\n",
       "      <td>A1tnTUPyr7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131186</th>\n",
       "      <td>131287</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1tnTUPyr7...</td>\n",
       "      <td>853009</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "      <td>./dataset/test_images/A1tnTUPyr7L.jpg</td>\n",
       "      <td>A1tnTUPyr7L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131187 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                         image_link  group_id  \\\n",
       "0            0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n",
       "1            1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "2            2  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "3            3  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "4            4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
       "...        ...                                                ...       ...   \n",
       "131182  131283  https://m.media-amazon.com/images/I/A1rVsIzEtk...    721522   \n",
       "131183  131284  https://m.media-amazon.com/images/I/A1rdvZ5zDd...    603688   \n",
       "131184  131285  https://m.media-amazon.com/images/I/A1rdvZ5zDd...    603688   \n",
       "131185  131286  https://m.media-amazon.com/images/I/A1tnTUPyr7...    853009   \n",
       "131186  131287  https://m.media-amazon.com/images/I/A1tnTUPyr7...    853009   \n",
       "\n",
       "                          entity_name                             image_path  \\\n",
       "0                              height  ./dataset/test_images/110EibNyclL.jpg   \n",
       "1                               width  ./dataset/test_images/11TU2clswzL.jpg   \n",
       "2                              height  ./dataset/test_images/11TU2clswzL.jpg   \n",
       "3                               depth  ./dataset/test_images/11TU2clswzL.jpg   \n",
       "4                               depth  ./dataset/test_images/11gHj8dhhrL.jpg   \n",
       "...                               ...                                    ...   \n",
       "131182  maximum_weight_recommendation  ./dataset/test_images/A1rVsIzEtkL.jpg   \n",
       "131183                    item_weight  ./dataset/test_images/A1rdvZ5zDdL.jpg   \n",
       "131184  maximum_weight_recommendation  ./dataset/test_images/A1rdvZ5zDdL.jpg   \n",
       "131185                    item_weight  ./dataset/test_images/A1tnTUPyr7L.jpg   \n",
       "131186  maximum_weight_recommendation  ./dataset/test_images/A1tnTUPyr7L.jpg   \n",
       "\n",
       "           image_id  \n",
       "0       110EibNyclL  \n",
       "1       11TU2clswzL  \n",
       "2       11TU2clswzL  \n",
       "3       11TU2clswzL  \n",
       "4       11gHj8dhhrL  \n",
       "...             ...  \n",
       "131182  A1rVsIzEtkL  \n",
       "131183  A1rdvZ5zDdL  \n",
       "131184  A1rdvZ5zDdL  \n",
       "131185  A1tnTUPyr7L  \n",
       "131186  A1tnTUPyr7L  \n",
       "\n",
       "[131187 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv['image_path'] = images_path\n",
    "test_csv['image_id'] = images_id\n",
    "test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv.to_csv('test_images_path_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotating Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "      <td>./dataset/train_images/61I9XdN6OFL.jpg</td>\n",
       "      <td>61I9XdN6OFL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id  entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight   \n",
       "\n",
       "  entity_value                              image_path     image_id  \n",
       "0   500.0 gram  ./dataset/train_images/61I9XdN6OFL.jpg  61I9XdN6OFL  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv['image_text'] = \"ashish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "      <td>./dataset/train_images/61I9XdN6OFL.jpg</td>\n",
       "      <td>61I9XdN6OFL</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "      <td>./dataset/train_images/71gSRbyXmoL.jpg</td>\n",
       "      <td>71gSRbyXmoL</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>./dataset/train_images/61BZ4zrjZXL.jpg</td>\n",
       "      <td>61BZ4zrjZXL</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>./dataset/train_images/612mrlqiI4L.jpg</td>\n",
       "      <td>612mrlqiI4L</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "      <td>./dataset/train_images/617Tl40LOXL.jpg</td>\n",
       "      <td>617Tl40LOXL</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263854</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612J1R1xHl...</td>\n",
       "      <td>558806</td>\n",
       "      <td>height</td>\n",
       "      <td>5.0 centimetre</td>\n",
       "      <td>./dataset/train_images/612J1R1xHlL.jpg</td>\n",
       "      <td>612J1R1xHlL</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263855</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61Blzh2+28...</td>\n",
       "      <td>470067</td>\n",
       "      <td>height</td>\n",
       "      <td>8.5 inch</td>\n",
       "      <td>./dataset/train_images/61Blzh2+28L.jpg</td>\n",
       "      <td>61Blzh2+28L</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263856</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51MsegDL9V...</td>\n",
       "      <td>204245</td>\n",
       "      <td>height</td>\n",
       "      <td>43.2 centimetre</td>\n",
       "      <td>./dataset/train_images/51MsegDL9VL.jpg</td>\n",
       "      <td>51MsegDL9VL</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263857</th>\n",
       "      <td>https://m.media-amazon.com/images/I/510KhVw4VS...</td>\n",
       "      <td>752266</td>\n",
       "      <td>height</td>\n",
       "      <td>9.1 centimetre</td>\n",
       "      <td>./dataset/train_images/510KhVw4VSL.jpg</td>\n",
       "      <td>510KhVw4VSL</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263858</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51lzTNLQ-6...</td>\n",
       "      <td>416664</td>\n",
       "      <td>height</td>\n",
       "      <td>27.5 centimetre</td>\n",
       "      <td>./dataset/train_images/51lzTNLQ-6S.jpg</td>\n",
       "      <td>51lzTNLQ-6S</td>\n",
       "      <td>ashish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263859 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_link  group_id  \\\n",
       "0       https://m.media-amazon.com/images/I/61I9XdN6OF...    748919   \n",
       "1       https://m.media-amazon.com/images/I/71gSRbyXmo...    916768   \n",
       "2       https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516   \n",
       "3       https://m.media-amazon.com/images/I/612mrlqiI4...    459516   \n",
       "4       https://m.media-amazon.com/images/I/617Tl40LOX...    731432   \n",
       "...                                                   ...       ...   \n",
       "263854  https://m.media-amazon.com/images/I/612J1R1xHl...    558806   \n",
       "263855  https://m.media-amazon.com/images/I/61Blzh2+28...    470067   \n",
       "263856  https://m.media-amazon.com/images/I/51MsegDL9V...    204245   \n",
       "263857  https://m.media-amazon.com/images/I/510KhVw4VS...    752266   \n",
       "263858  https://m.media-amazon.com/images/I/51lzTNLQ-6...    416664   \n",
       "\n",
       "        entity_name     entity_value                              image_path  \\\n",
       "0       item_weight       500.0 gram  ./dataset/train_images/61I9XdN6OFL.jpg   \n",
       "1       item_volume          1.0 cup  ./dataset/train_images/71gSRbyXmoL.jpg   \n",
       "2       item_weight       0.709 gram  ./dataset/train_images/61BZ4zrjZXL.jpg   \n",
       "3       item_weight       0.709 gram  ./dataset/train_images/612mrlqiI4L.jpg   \n",
       "4       item_weight   1400 milligram  ./dataset/train_images/617Tl40LOXL.jpg   \n",
       "...             ...              ...                                     ...   \n",
       "263854       height   5.0 centimetre  ./dataset/train_images/612J1R1xHlL.jpg   \n",
       "263855       height         8.5 inch  ./dataset/train_images/61Blzh2+28L.jpg   \n",
       "263856       height  43.2 centimetre  ./dataset/train_images/51MsegDL9VL.jpg   \n",
       "263857       height   9.1 centimetre  ./dataset/train_images/510KhVw4VSL.jpg   \n",
       "263858       height  27.5 centimetre  ./dataset/train_images/51lzTNLQ-6S.jpg   \n",
       "\n",
       "           image_id image_text  \n",
       "0       61I9XdN6OFL     ashish  \n",
       "1       71gSRbyXmoL     ashish  \n",
       "2       61BZ4zrjZXL     ashish  \n",
       "3       612mrlqiI4L     ashish  \n",
       "4       617Tl40LOXL     ashish  \n",
       "...             ...        ...  \n",
       "263854  612J1R1xHlL     ashish  \n",
       "263855  61Blzh2+28L     ashish  \n",
       "263856  51MsegDL9VL     ashish  \n",
       "263857  510KhVw4VSL     ashish  \n",
       "263858  51lzTNLQ-6S     ashish  \n",
       "\n",
       "[263859 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/110EibNycl...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "      <td>./dataset/test_images/110EibNyclL.jpg</td>\n",
       "      <td>110EibNyclL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>width</td>\n",
       "      <td>./dataset/test_images/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>height</td>\n",
       "      <td>./dataset/test_images/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "      <td>./dataset/test_images/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11gHj8dhhr...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "      <td>./dataset/test_images/11gHj8dhhrL.jpg</td>\n",
       "      <td>11gHj8dhhrL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131182</th>\n",
       "      <td>131283</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rVsIzEtk...</td>\n",
       "      <td>721522</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "      <td>./dataset/test_images/A1rVsIzEtkL.jpg</td>\n",
       "      <td>A1rVsIzEtkL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131183</th>\n",
       "      <td>131284</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rdvZ5zDd...</td>\n",
       "      <td>603688</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>./dataset/test_images/A1rdvZ5zDdL.jpg</td>\n",
       "      <td>A1rdvZ5zDdL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131184</th>\n",
       "      <td>131285</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rdvZ5zDd...</td>\n",
       "      <td>603688</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "      <td>./dataset/test_images/A1rdvZ5zDdL.jpg</td>\n",
       "      <td>A1rdvZ5zDdL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131185</th>\n",
       "      <td>131286</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1tnTUPyr7...</td>\n",
       "      <td>853009</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>./dataset/test_images/A1tnTUPyr7L.jpg</td>\n",
       "      <td>A1tnTUPyr7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131186</th>\n",
       "      <td>131287</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1tnTUPyr7...</td>\n",
       "      <td>853009</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "      <td>./dataset/test_images/A1tnTUPyr7L.jpg</td>\n",
       "      <td>A1tnTUPyr7L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131187 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                         image_link  group_id  \\\n",
       "0            0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n",
       "1            1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "2            2  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "3            3  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "4            4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
       "...        ...                                                ...       ...   \n",
       "131182  131283  https://m.media-amazon.com/images/I/A1rVsIzEtk...    721522   \n",
       "131183  131284  https://m.media-amazon.com/images/I/A1rdvZ5zDd...    603688   \n",
       "131184  131285  https://m.media-amazon.com/images/I/A1rdvZ5zDd...    603688   \n",
       "131185  131286  https://m.media-amazon.com/images/I/A1tnTUPyr7...    853009   \n",
       "131186  131287  https://m.media-amazon.com/images/I/A1tnTUPyr7...    853009   \n",
       "\n",
       "                          entity_name                             image_path  \\\n",
       "0                              height  ./dataset/test_images/110EibNyclL.jpg   \n",
       "1                               width  ./dataset/test_images/11TU2clswzL.jpg   \n",
       "2                              height  ./dataset/test_images/11TU2clswzL.jpg   \n",
       "3                               depth  ./dataset/test_images/11TU2clswzL.jpg   \n",
       "4                               depth  ./dataset/test_images/11gHj8dhhrL.jpg   \n",
       "...                               ...                                    ...   \n",
       "131182  maximum_weight_recommendation  ./dataset/test_images/A1rVsIzEtkL.jpg   \n",
       "131183                    item_weight  ./dataset/test_images/A1rdvZ5zDdL.jpg   \n",
       "131184  maximum_weight_recommendation  ./dataset/test_images/A1rdvZ5zDdL.jpg   \n",
       "131185                    item_weight  ./dataset/test_images/A1tnTUPyr7L.jpg   \n",
       "131186  maximum_weight_recommendation  ./dataset/test_images/A1tnTUPyr7L.jpg   \n",
       "\n",
       "           image_id  \n",
       "0       110EibNyclL  \n",
       "1       11TU2clswzL  \n",
       "2       11TU2clswzL  \n",
       "3       11TU2clswzL  \n",
       "4       11gHj8dhhrL  \n",
       "...             ...  \n",
       "131182  A1rVsIzEtkL  \n",
       "131183  A1rdvZ5zDdL  \n",
       "131184  A1rdvZ5zDdL  \n",
       "131185  A1tnTUPyr7L  \n",
       "131186  A1tnTUPyr7L  \n",
       "\n",
       "[131187 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ashish = pd.read_csv('/home/bheeshmsharma/ashish/student_resource_3/student_resource 3/test_images_path_full.csv')\n",
    "ashish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c9cd7d6e4f402d925f535d3bfee09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm, trange\n",
    "import gc\n",
    "\n",
    "def load_image_to_array(path):\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            img_array = np.array(img)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to open image {path}: {e}\")\n",
    "\n",
    "image_paths = ashish.image_path.tolist()[30000+20000:]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = {executor.submit(load_image_to_array, path): path for path in image_paths}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        try:\n",
    "            img_array = future.result()\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv['image_text'] = \"ashish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_paths_csv = test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['./dataset/test_images/110EibNyclL.jpg']</td>\n",
       "      <td>['1 1 1 ha ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['./dataset/test_images/11TU2clswzL.jpg']</td>\n",
       "      <td>['size width length one size 42cm/1654\" 200cm/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['./dataset/test_images/11TU2clswzL.jpg']</td>\n",
       "      <td>['size width length one size 42cm/1654\" 200cm/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['./dataset/test_images/11TU2clswzL.jpg']</td>\n",
       "      <td>['size width length one size 42cm/1654\" 200cm/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['./dataset/test_images/11gHj8dhhrL.jpg']</td>\n",
       "      <td>['azis width length 1 1050cm/413\" 90cm/3543\" ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95737</th>\n",
       "      <td>['./dataset/test_images/618uninNqxL.jpg']</td>\n",
       "      <td>['pease 1 sign our guest bool 0 8 inches ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95738</th>\n",
       "      <td>['./dataset/test_images/618unkgMfGL.jpg']</td>\n",
       "      <td>['anodic oxidation surface weight 1850z base b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95739</th>\n",
       "      <td>['./dataset/test_images/618uoCgdK-L.jpg']</td>\n",
       "      <td>['hay que en la caja 618 9 cm cm 1 803cm led e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95740</th>\n",
       "      <td>['./dataset/test_images/618uqbW4i5L.jpg']</td>\n",
       "      <td>['my bag story 31 cm 1204 inches 0 nie 4 9 cm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95741</th>\n",
       "      <td>['./dataset/test_images/618usm52ENL.jpg']</td>\n",
       "      <td>['product size 26cm 24cm 20cm 8cm 8cm 8cm 1000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95742 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        image_id  \\\n",
       "0      ['./dataset/test_images/110EibNyclL.jpg']   \n",
       "1      ['./dataset/test_images/11TU2clswzL.jpg']   \n",
       "2      ['./dataset/test_images/11TU2clswzL.jpg']   \n",
       "3      ['./dataset/test_images/11TU2clswzL.jpg']   \n",
       "4      ['./dataset/test_images/11gHj8dhhrL.jpg']   \n",
       "...                                          ...   \n",
       "95737  ['./dataset/test_images/618uninNqxL.jpg']   \n",
       "95738  ['./dataset/test_images/618unkgMfGL.jpg']   \n",
       "95739  ['./dataset/test_images/618uoCgdK-L.jpg']   \n",
       "95740  ['./dataset/test_images/618uqbW4i5L.jpg']   \n",
       "95741  ['./dataset/test_images/618usm52ENL.jpg']   \n",
       "\n",
       "                                                    text  \n",
       "0                                          ['1 1 1 ha ']  \n",
       "1      ['size width length one size 42cm/1654\" 200cm/...  \n",
       "2      ['size width length one size 42cm/1654\" 200cm/...  \n",
       "3      ['size width length one size 42cm/1654\" 200cm/...  \n",
       "4        ['azis width length 1 1050cm/413\" 90cm/3543\" ']  \n",
       "...                                                  ...  \n",
       "95737        ['pease 1 sign our guest bool 0 8 inches ']  \n",
       "95738  ['anodic oxidation surface weight 1850z base b...  \n",
       "95739  ['hay que en la caja 618 9 cm cm 1 803cm led e...  \n",
       "95740  ['my bag story 31 cm 1204 inches 0 nie 4 9 cm ...  \n",
       "95741  ['product size 26cm 24cm 20cm 8cm 8cm 8cm 1000...  \n",
       "\n",
       "[95742 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_csv = pd.read_csv('/home/bheeshmsharma/ashish/student_resource_3/student_resource 3/test_output.csv')\n",
    "test_text_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110EibNyclL</td>\n",
       "      <td>['1 1 1 ha ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11TU2clswzL</td>\n",
       "      <td>['size width length one size 42cm/1654\" 200cm/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11TU2clswzL</td>\n",
       "      <td>['size width length one size 42cm/1654\" 200cm/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11TU2clswzL</td>\n",
       "      <td>['size width length one size 42cm/1654\" 200cm/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11gHj8dhhrL</td>\n",
       "      <td>['azis width length 1 1050cm/413\" 90cm/3543\" ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95737</th>\n",
       "      <td>618uninNqxL</td>\n",
       "      <td>['pease 1 sign our guest bool 0 8 inches ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95738</th>\n",
       "      <td>618unkgMfGL</td>\n",
       "      <td>['anodic oxidation surface weight 1850z base b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95739</th>\n",
       "      <td>618uoCgdK-L</td>\n",
       "      <td>['hay que en la caja 618 9 cm cm 1 803cm led e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95740</th>\n",
       "      <td>618uqbW4i5L</td>\n",
       "      <td>['my bag story 31 cm 1204 inches 0 nie 4 9 cm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95741</th>\n",
       "      <td>618usm52ENL</td>\n",
       "      <td>['product size 26cm 24cm 20cm 8cm 8cm 8cm 1000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95742 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id                                               text\n",
       "0      110EibNyclL                                      ['1 1 1 ha ']\n",
       "1      11TU2clswzL  ['size width length one size 42cm/1654\" 200cm/...\n",
       "2      11TU2clswzL  ['size width length one size 42cm/1654\" 200cm/...\n",
       "3      11TU2clswzL  ['size width length one size 42cm/1654\" 200cm/...\n",
       "4      11gHj8dhhrL    ['azis width length 1 1050cm/413\" 90cm/3543\" ']\n",
       "...            ...                                                ...\n",
       "95737  618uninNqxL        ['pease 1 sign our guest bool 0 8 inches ']\n",
       "95738  618unkgMfGL  ['anodic oxidation surface weight 1850z base b...\n",
       "95739  618uoCgdK-L  ['hay que en la caja 618 9 cm cm 1 803cm led e...\n",
       "95740  618uqbW4i5L  ['my bag story 31 cm 1204 inches 0 nie 4 9 cm ...\n",
       "95741  618usm52ENL  ['product size 26cm 24cm 20cm 8cm 8cm 8cm 1000...\n",
       "\n",
       "[95742 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_csv.image_id = test_text_csv.image_id.apply(lambda x: x.split('[')[-1].split(']')[0])\n",
    "test_text_csv.image_id = test_text_csv.image_id.apply(lambda x: x.split('/')[-1].split('.')[0])\n",
    "for i in range(len(test_text_csv)):\n",
    "    if test_images_paths_csv.image_id.values[i] == test_text_csv.image_id.values[i]:\n",
    "        test_images_paths_csv.image_text.values[i] = test_text_csv.text.values[i]\n",
    "test_text_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95742"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_images_paths_csv.image_text != 'ashish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/110EibNycl...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "      <td>./dataset/test_images/110EibNyclL.jpg</td>\n",
       "      <td>110EibNyclL</td>\n",
       "      <td>['1 1 1 ha ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>width</td>\n",
       "      <td>./dataset/test_images/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL</td>\n",
       "      <td>['size width length one size 42cm/1654\" 200cm/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>height</td>\n",
       "      <td>./dataset/test_images/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL</td>\n",
       "      <td>['size width length one size 42cm/1654\" 200cm/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "      <td>./dataset/test_images/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL</td>\n",
       "      <td>['size width length one size 42cm/1654\" 200cm/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11gHj8dhhr...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "      <td>./dataset/test_images/11gHj8dhhrL.jpg</td>\n",
       "      <td>11gHj8dhhrL</td>\n",
       "      <td>['azis width length 1 1050cm/413\" 90cm/3543\" ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95737</th>\n",
       "      <td>95811</td>\n",
       "      <td>https://m.media-amazon.com/images/I/618uninNqx...</td>\n",
       "      <td>119607</td>\n",
       "      <td>width</td>\n",
       "      <td>./dataset/test_images/618uninNqxL.jpg</td>\n",
       "      <td>618uninNqxL</td>\n",
       "      <td>['pease 1 sign our guest bool 0 8 inches ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95738</th>\n",
       "      <td>95812</td>\n",
       "      <td>https://m.media-amazon.com/images/I/618unkgMfG...</td>\n",
       "      <td>647208</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>./dataset/test_images/618unkgMfGL.jpg</td>\n",
       "      <td>618unkgMfGL</td>\n",
       "      <td>['anodic oxidation surface weight 1850z base b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95739</th>\n",
       "      <td>95813</td>\n",
       "      <td>https://m.media-amazon.com/images/I/618uoCgdK-...</td>\n",
       "      <td>625310</td>\n",
       "      <td>width</td>\n",
       "      <td>./dataset/test_images/618uoCgdK-L.jpg</td>\n",
       "      <td>618uoCgdK-L</td>\n",
       "      <td>['hay que en la caja 618 9 cm cm 1 803cm led e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95740</th>\n",
       "      <td>95814</td>\n",
       "      <td>https://m.media-amazon.com/images/I/618uqbW4i5...</td>\n",
       "      <td>844474</td>\n",
       "      <td>height</td>\n",
       "      <td>./dataset/test_images/618uqbW4i5L.jpg</td>\n",
       "      <td>618uqbW4i5L</td>\n",
       "      <td>['my bag story 31 cm 1204 inches 0 nie 4 9 cm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95741</th>\n",
       "      <td>95815</td>\n",
       "      <td>https://m.media-amazon.com/images/I/618usm52EN...</td>\n",
       "      <td>403664</td>\n",
       "      <td>depth</td>\n",
       "      <td>./dataset/test_images/618usm52ENL.jpg</td>\n",
       "      <td>618usm52ENL</td>\n",
       "      <td>['product size 26cm 24cm 20cm 8cm 8cm 8cm 1000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95742 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                         image_link  group_id  \\\n",
       "0          0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n",
       "1          1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "2          2  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "3          3  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "4          4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
       "...      ...                                                ...       ...   \n",
       "95737  95811  https://m.media-amazon.com/images/I/618uninNqx...    119607   \n",
       "95738  95812  https://m.media-amazon.com/images/I/618unkgMfG...    647208   \n",
       "95739  95813  https://m.media-amazon.com/images/I/618uoCgdK-...    625310   \n",
       "95740  95814  https://m.media-amazon.com/images/I/618uqbW4i5...    844474   \n",
       "95741  95815  https://m.media-amazon.com/images/I/618usm52EN...    403664   \n",
       "\n",
       "       entity_name                             image_path     image_id  \\\n",
       "0           height  ./dataset/test_images/110EibNyclL.jpg  110EibNyclL   \n",
       "1            width  ./dataset/test_images/11TU2clswzL.jpg  11TU2clswzL   \n",
       "2           height  ./dataset/test_images/11TU2clswzL.jpg  11TU2clswzL   \n",
       "3            depth  ./dataset/test_images/11TU2clswzL.jpg  11TU2clswzL   \n",
       "4            depth  ./dataset/test_images/11gHj8dhhrL.jpg  11gHj8dhhrL   \n",
       "...            ...                                    ...          ...   \n",
       "95737        width  ./dataset/test_images/618uninNqxL.jpg  618uninNqxL   \n",
       "95738  item_weight  ./dataset/test_images/618unkgMfGL.jpg  618unkgMfGL   \n",
       "95739        width  ./dataset/test_images/618uoCgdK-L.jpg  618uoCgdK-L   \n",
       "95740       height  ./dataset/test_images/618uqbW4i5L.jpg  618uqbW4i5L   \n",
       "95741        depth  ./dataset/test_images/618usm52ENL.jpg  618usm52ENL   \n",
       "\n",
       "                                              image_text  \n",
       "0                                          ['1 1 1 ha ']  \n",
       "1      ['size width length one size 42cm/1654\" 200cm/...  \n",
       "2      ['size width length one size 42cm/1654\" 200cm/...  \n",
       "3      ['size width length one size 42cm/1654\" 200cm/...  \n",
       "4        ['azis width length 1 1050cm/413\" 90cm/3543\" ']  \n",
       "...                                                  ...  \n",
       "95737        ['pease 1 sign our guest bool 0 8 inches ']  \n",
       "95738  ['anodic oxidation surface weight 1850z base b...  \n",
       "95739  ['hay que en la caja 618 9 cm cm 1 803cm led e...  \n",
       "95740  ['my bag story 31 cm 1204 inches 0 nie 4 9 cm ...  \n",
       "95741  ['product size 26cm 24cm 20cm 8cm 8cm 8cm 1000...  \n",
       "\n",
       "[95742 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_images_paths_csv = test_images_paths_csv.iloc[:sum(test_images_paths_csv.image_text != 'ashish'),:].drop(columns=['image_link'])\n",
    "test_images_paths_csv = test_images_paths_csv.iloc[:sum(test_images_paths_csv.image_text != 'ashish'),:]\n",
    "# test_images_paths_csv.to_csv('test_paths_text.csv', index=False)\n",
    "test_images_paths_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_paths_csv.to_csv('test_images_path_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset/train_images/41NH8WgeBOL.jpg'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.image_path.values[1096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(Image.open(train_csv.image_path.values[1096]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from tqdm.auto import trange\n",
    "# import easyocr\n",
    "# import numpy as np\n",
    "# import re\n",
    "# import csv\n",
    "# import os\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# reader = easyocr.Reader(['en'])\n",
    "\n",
    "# # File path for the CSV\n",
    "# file_path = 'output.csv'\n",
    "\n",
    "# # Check if file exists and has content\n",
    "# file_exists = os.path.isfile(file_path) and os.stat(file_path).st_size > 0\n",
    "\n",
    "# # Open the CSV file in append mode\n",
    "# with open(file_path, 'a', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "    \n",
    "#     # Write the header row if file is new\n",
    "#     if not file_exists:\n",
    "#         writer.writerow(['image_id', 'text'])\n",
    "    \n",
    "#     for i in range(len(train_csv)):\n",
    "#         try:\n",
    "#             image_path = train_csv.image_path.values[i]\n",
    "#             img = np.array(Image.open(image_path))\n",
    "#             results = reader.readtext(img, batch_size=256, workers=1, rotation_info=[90, 180, 270])\n",
    "            \n",
    "#             sentence = []\n",
    "#             for (bbox, text, prob) in results:\n",
    "#                 sentence.append(text)\n",
    "#             sentence = ' '.join(sentence)\n",
    "            \n",
    "#             cleaned_sentence = re.sub(r'[,\\?\\.\\!\\-\\;\\:\\%\\'\\`\\{}()@#$%^&*\\+\\[\\]\\_]+', '', sentence).lower() + ' '\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing image {image_path}: {e}\")\n",
    "#             cleaned_sentence = ' '\n",
    "        \n",
    "#         # Write the image_id and cleaned_sentence to the CSV file\n",
    "#         writer.writerow([[image_path], [cleaned_sentence]])\n",
    "        \n",
    "#         print(i, end=\" \")\n",
    "#         if i % 100 == 0:\n",
    "#             file.flush()\n",
    "#             clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95701 95702 95703 95704 95705 95706 95707 95708 95709 95710 95711 95712 95713 95714 95715 95716 95717 95718 95719 95720 95721 95722 95723 95724 95725 95726 95727 95728 95729 95730 95731 95732 95733 95734 95735 95736 95737 95738 95739 95740 95741 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m image_path \u001b[38;5;241m=\u001b[39m test_csv\u001b[38;5;241m.\u001b[39mimage_path\u001b[38;5;241m.\u001b[39mvalues[i]\n\u001b[1;32m     29\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(image_path))\n\u001b[0;32m---> 30\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotation_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m270\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m sentence \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (bbox, text, prob) \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_env_aku/lib/python3.11/site-packages/easyocr/easyocr.py:456\u001b[0m, in \u001b[0;36mReader.readtext\u001b[0;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03mimage: file path or numpy-array or a byte stream object\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    454\u001b[0m img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(image)\n\u001b[0;32m--> 456\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreformat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[1;32m    467\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m horizontal_list[\u001b[38;5;241m0\u001b[39m], free_list[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_env_aku/lib/python3.11/site-packages/easyocr/easyocr.py:321\u001b[0m, in \u001b[0;36mReader.detect\u001b[0;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reformat:\n\u001b[1;32m    319\u001b[0m     img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(img)\n\u001b[0;32m--> 321\u001b[0m text_box_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_textbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m horizontal_list_agg, free_list_agg \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_box \u001b[38;5;129;01min\u001b[39;00m text_box_list:\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_env_aku/lib/python3.11/site-packages/easyocr/detection.py:95\u001b[0m, in \u001b[0;36mget_textbox\u001b[0;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     94\u001b[0m estimate_num_chars \u001b[38;5;241m=\u001b[39m optimal_num_chars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m bboxes_list, polys_list \u001b[38;5;241m=\u001b[39m \u001b[43mtest_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimate_num_chars:\n\u001b[1;32m    100\u001b[0m     polys_list \u001b[38;5;241m=\u001b[39m [[p \u001b[38;5;28;01mfor\u001b[39;00m p, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(polys, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mabs\u001b[39m(optimal_num_chars \u001b[38;5;241m-\u001b[39m x[\u001b[38;5;241m1\u001b[39m]))]\n\u001b[1;32m    101\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m polys \u001b[38;5;129;01min\u001b[39;00m polys_list]\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_env_aku/lib/python3.11/site-packages/easyocr/detection.py:41\u001b[0m, in \u001b[0;36mtest_net\u001b[0;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# preprocessing\u001b[39;00m\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mtranspose(normalizeMeanVariance(n_img), (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     40\u001b[0m      \u001b[38;5;28;01mfor\u001b[39;00m n_img \u001b[38;5;129;01min\u001b[39;00m img_resized_list]\n\u001b[0;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(x))\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm.auto import trange\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# File path for the CSV\n",
    "file_path = 'test_output.csv'\n",
    "\n",
    "# Check if file exists and has content\n",
    "file_exists = os.path.isfile(file_path) and os.stat(file_path).st_size > 0\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(file_path, 'a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the header row if file is new\n",
    "    if not file_exists:\n",
    "        writer.writerow(['image_id', 'text'])\n",
    "    \n",
    "    for i in range(len(test_csv)):\n",
    "        try:\n",
    "            image_path = test_csv.image_path.values[i]\n",
    "            img = np.array(Image.open(image_path))\n",
    "            results = reader.readtext(img, batch_size=256, workers=1, rotation_info=[90, 180, 270])\n",
    "            \n",
    "            sentence = []\n",
    "            for (bbox, text, prob) in results:\n",
    "                sentence.append(text)\n",
    "            sentence = ' '.join(sentence)\n",
    "            \n",
    "            cleaned_sentence = re.sub(r'[,\\?\\.\\!\\-\\;\\:\\%\\'\\`\\{}()@#$%^&*\\+\\[\\]\\_]+', '', sentence).lower() + ' '\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "            cleaned_sentence = ' '\n",
    "        \n",
    "        # Write the image_id and cleaned_sentence to the CSV file\n",
    "        writer.writerow([[image_path], [cleaned_sentence]])\n",
    "        \n",
    "        print(i, end=\" \")\n",
    "        if i % 100 == 0:\n",
    "            file.flush()\n",
    "            clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from tqdm.auto import trange\n",
    "# import easyocr\n",
    "# import numpy as np\n",
    "# import re\n",
    "# from IPython.display import clear_output\n",
    "# import csv\n",
    "# reader = easyocr.Reader(['en'])\n",
    "\n",
    "# with open('output.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     for i in trange(len(train_csv)):\n",
    "#         try:\n",
    "#             image = train_csv.image_path.values[i]\n",
    "#             img = np.array(Image.open(image))\n",
    "#             results = reader.readtext(img, batch_size=256, workers=1, rotation_info=[90, 180, 270])\n",
    "#             # results = reader.readtext(img, batch_size=256, workers=1)\n",
    "            \n",
    "#             sentence = []\n",
    "#             for (bbox, text, prob) in results:\n",
    "#                 sentence.append(text)\n",
    "#             sentence = ' '.join(sentence)\n",
    "            \n",
    "#             cleaned_sentence = re.sub(r'[,\\?\\.\\!\\-\\;\\:\\%\\'\\`\\{}()@#$%^&*\\+\\[\\]\\_]+', '', sentence).lower() + ' '\n",
    "#         except:\n",
    "#             cleaned_sentence = ' '\n",
    "        \n",
    "#         writer.writerow([cleaned_sentence])\n",
    "#         file.write(cleaned_sentence + '\\n')\n",
    "#         file.flush()\n",
    "        \n",
    "#         print(i, end=\" \")\n",
    "#         if i % 50 == 0:\n",
    "#             clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from tqdm.auto import trange\n",
    "# import easyocr\n",
    "# import numpy as np\n",
    "# import re\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# reader = easyocr.Reader(['en'])\n",
    "\n",
    "# # Open the file in append mode\n",
    "# with open('output.txt', 'a') as file:\n",
    "#     for i in trange(len(train_csv.image_path.values[1096:])):\n",
    "#         image = train_csv.image_path.values[1097+i]\n",
    "#         img = np.array(Image.open(image))\n",
    "#         results = reader.readtext(img, batch_size=256, workers=1, rotation_info=[90, 180, 270])\n",
    "        \n",
    "#         sentence = []\n",
    "#         for (bbox, text, prob) in results:\n",
    "#             sentence.append(text)\n",
    "#         sentence = ' '.join(sentence)\n",
    "        \n",
    "#         cleaned_sentence = re.sub(r'[,\\?\\.\\!\\-\\;\\:\\%\\'\\`\\{}()@#$%^&*\\+\\[\\]\\_]+', '', sentence).lower() + ' '\n",
    "        \n",
    "#         # Write to file and flush\n",
    "#         file.write(cleaned_sentence + '\\n')  # Ensure each sentence is on a new line\n",
    "#         file.flush()\n",
    "        \n",
    "#         # print(i, end=\" \")\n",
    "#         # if i % 100 == 0:\n",
    "#         #     clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "# # import torch\n",
    "# # torch.backends.cudnn.enabled = False\n",
    "# # !export CUDA_VISIBLE_DEVICES=1\n",
    "# # import torch\n",
    "# # torch.backends.cudnn.enabled = False\n",
    "# from PIL import Image\n",
    "# from tqdm.auto import trange\n",
    "# import easyocr\n",
    "# reader = easyocr.Reader(['en'])\n",
    "# from IPython.display import clear_output\n",
    "# with open('output.txt', 'a') as file:\n",
    "\n",
    "#     # for i in trange(len(train_csv)):\n",
    "#     for i in range(len(train_csv)):\n",
    "#         # if i == 10:\n",
    "#         #     break\n",
    "        \n",
    "#         image = train_csv.image_path.values[i]\n",
    "#         img = np.array(Image.open(image))\n",
    "#         # results = reader.readtext(img)\n",
    "#         # results = reader.readtext(img, batch_size = 10, workers=1)\n",
    "#         results = reader.readtext(img, batch_size = 256, workers=5, rotation_info=[90, 180 ,270])\n",
    "#         # results = reader.readtext(img, rotation_info=[90, 180 ,270])\n",
    "#         sentence = []\n",
    "#         for (bbox, text, prob) in results:\n",
    "#             # print(f\"Detected Text: {text} (Confidence: {prob:.2f})\")\n",
    "#             sentence.append(text)\n",
    "#         sentence = ' '.join(sentence)\n",
    "#         # print(train_csv.entity_name.values[i], train_csv.entity_value.values[i], sentence)\n",
    "#         cleaned_sentence = re.sub(r'[,\\?\\.\\!\\-\\;\\:\\%\\'\\`\\{}()@#$%^&*\\+\\[\\]\\_]+', '', sentence).lower() + ' '\n",
    "#         # print(cleaned_sentence)\n",
    "#         file.write(cleaned_sentence)\n",
    "#         # train_csv.loc[i,'image_text'] = cleaned_sentence\n",
    "#         # print('*'*50)\n",
    "#         print(i, end=\" \")\n",
    "#         if i % 100 == 0:\n",
    "#             clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
